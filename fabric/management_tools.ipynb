{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook has some utilities to manage the already deployed cluster. \n",
    "- uninstall DYNAMOS\n",
    "- trigger VFL\n",
    "- ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FABlib API References Examples\n",
    "\n",
    "- [fablib.show_config](https://fabric-fablib.readthedocs.io/en/latest/fablib.html#fabrictestbed_extensions.fablib.fablib.FablibManager.show_config)\n",
    "- [fablib.list_sites](https://fabric-fablib.readthedocs.io/en/latest/fablib.html#fabrictestbed_extensions.fablib.fablib.FablibManager.list_sites)\n",
    "- [fablib.list_hosts](https://fabric-fablib.readthedocs.io/en/latest/fablib.html#fabrictestbed_extensions.fablib.fablib.FablibManager.list_hosts)\n",
    "- [fablib.new_slice](https://fabric-fablib.readthedocs.io/en/latest/fablib.html#fabrictestbed_extensions.fablib.fablib.FablibManager.new_slice)\n",
    "- [slice.add_node](https://fabric-fablib.readthedocs.io/en/latest/slice.html#fabrictestbed_extensions.fablib.slice.Slice.add_node)\n",
    "- [slice.submit](https://fabric-fablib.readthedocs.io/en/latest/slice.html#fabrictestbed_extensions.fablib.slice.Slice.submit)\n",
    "- [slice.get_nodes](https://fabric-fablib.readthedocs.io/en/latest/slice.html#fabrictestbed_extensions.fablib.slice.Slice.get_nodes)\n",
    "- [slice.list_nodes](https://fabric-fablib.readthedocs.io/en/latest/slice.html#fabrictestbed_extensions.fablib.slice.Slice.list_nodesß)\n",
    "- [slice.show](https://fabric-fablib.readthedocs.io/en/latest/slice.html#fabrictestbed_extensions.fablib.slice.Slice.show)\n",
    "- [node.execute](https://fabric-fablib.readthedocs.io/en/latest/node.html#fabrictestbed_extensions.fablib.node.Node.execute)\n",
    "- [slice.delete](https://fabric-fablib.readthedocs.io/en/latest/slice.html#fabrictestbed_extensions.fablib.slice.Slice.delete) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: koufalex@gmail.com bastion key is valid!\n",
      "Configuration is valid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ff707 tr:nth-child(even) {\n",
       "  background: #dbf3ff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_ff707 tr:nth-child(odd) {\n",
       "  background: #ffffff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_ff707 caption {\n",
       "  text-align: center;\n",
       "  font-size: 150%;\n",
       "}\n",
       "#T_ff707_row0_col0, #T_ff707_row0_col1, #T_ff707_row1_col0, #T_ff707_row1_col1, #T_ff707_row2_col0, #T_ff707_row2_col1, #T_ff707_row3_col0, #T_ff707_row3_col1, #T_ff707_row4_col0, #T_ff707_row4_col1, #T_ff707_row5_col0, #T_ff707_row5_col1, #T_ff707_row6_col0, #T_ff707_row6_col1, #T_ff707_row7_col0, #T_ff707_row7_col1, #T_ff707_row8_col0, #T_ff707_row8_col1, #T_ff707_row9_col0, #T_ff707_row9_col1, #T_ff707_row10_col0, #T_ff707_row10_col1, #T_ff707_row11_col0, #T_ff707_row11_col1, #T_ff707_row12_col0, #T_ff707_row12_col1, #T_ff707_row13_col0, #T_ff707_row13_col1, #T_ff707_row14_col0, #T_ff707_row14_col1, #T_ff707_row15_col0, #T_ff707_row15_col1, #T_ff707_row16_col0, #T_ff707_row16_col1, #T_ff707_row17_col0, #T_ff707_row17_col1, #T_ff707_row18_col0, #T_ff707_row18_col1, #T_ff707_row19_col0, #T_ff707_row19_col1 {\n",
       "  text-align: left;\n",
       "  border: 1px #231f20 solid !important;\n",
       "  overwrite: False;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ff707\">\n",
       "  <caption>FABlib Config</caption>\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row0_col0\" class=\"data row0 col0\" >Orchestrator</td>\n",
       "      <td id=\"T_ff707_row0_col1\" class=\"data row0 col1\" >orchestrator.fabric-testbed.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row1_col0\" class=\"data row1 col0\" >Credential Manager</td>\n",
       "      <td id=\"T_ff707_row1_col1\" class=\"data row1 col1\" >cm.fabric-testbed.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row2_col0\" class=\"data row2 col0\" >Core API</td>\n",
       "      <td id=\"T_ff707_row2_col1\" class=\"data row2 col1\" >uis.fabric-testbed.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row3_col0\" class=\"data row3 col0\" >Artifact Manager</td>\n",
       "      <td id=\"T_ff707_row3_col1\" class=\"data row3 col1\" >artifacts.fabric-testbed.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row4_col0\" class=\"data row4 col0\" >Token File</td>\n",
       "      <td id=\"T_ff707_row4_col1\" class=\"data row4 col1\" >/home/fabric/.tokens.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row5_col0\" class=\"data row5 col0\" >Project ID</td>\n",
       "      <td id=\"T_ff707_row5_col1\" class=\"data row5 col1\" >49f65ad7-d8a2-4ab9-8ca0-ba777a2e0ea2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row6_col0\" class=\"data row6 col0\" >Bastion Host</td>\n",
       "      <td id=\"T_ff707_row6_col1\" class=\"data row6 col1\" >bastion.fabric-testbed.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row7_col0\" class=\"data row7 col0\" >Bastion Username</td>\n",
       "      <td id=\"T_ff707_row7_col1\" class=\"data row7 col1\" >koufalex_0000215529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row8_col0\" class=\"data row8 col0\" >Bastion Private Key File</td>\n",
       "      <td id=\"T_ff707_row8_col1\" class=\"data row8 col1\" >/home/fabric/work/fabric_config/fabric_bastion_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row9_col0\" class=\"data row9 col0\" >Slice Public Key File</td>\n",
       "      <td id=\"T_ff707_row9_col1\" class=\"data row9 col1\" >/home/fabric/work/fabric_config/slice_key.pub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row10_col0\" class=\"data row10 col0\" >Slice Private Key File</td>\n",
       "      <td id=\"T_ff707_row10_col1\" class=\"data row10 col1\" >/home/fabric/work/fabric_config/slice_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row11_col0\" class=\"data row11 col0\" >Sites to avoid</td>\n",
       "      <td id=\"T_ff707_row11_col1\" class=\"data row11 col1\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row12_col0\" class=\"data row12 col0\" >SSH Command Line</td>\n",
       "      <td id=\"T_ff707_row12_col1\" class=\"data row12 col1\" >ssh -i {{ _self_.private_ssh_key_file }} -F /home/fabric/work/fabric_config/ssh_config {{ _self_.username }}@{{ _self_.management_ip }}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row13_col0\" class=\"data row13 col0\" >Log Level</td>\n",
       "      <td id=\"T_ff707_row13_col1\" class=\"data row13 col1\" >INFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row14_col0\" class=\"data row14 col0\" >Log File</td>\n",
       "      <td id=\"T_ff707_row14_col1\" class=\"data row14 col1\" >/tmp/fablib/fablib.log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row15_col0\" class=\"data row15 col0\" >Bastion SSH Config File</td>\n",
       "      <td id=\"T_ff707_row15_col1\" class=\"data row15 col1\" >/home/fabric/work/fabric_config/ssh_config</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row16_col0\" class=\"data row16 col0\" >Fabric Meta Data Release Tag</td>\n",
       "      <td id=\"T_ff707_row16_col1\" class=\"data row16 col1\" >main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row17_col0\" class=\"data row17 col0\" >Version</td>\n",
       "      <td id=\"T_ff707_row17_col1\" class=\"data row17 col1\" >1.9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row18_col0\" class=\"data row18 col0\" >Data directory</td>\n",
       "      <td id=\"T_ff707_row18_col1\" class=\"data row18 col1\" >/tmp/fablib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff707_row19_col0\" class=\"data row19 col0\" >Project Name</td>\n",
       "      <td id=\"T_ff707_row19_col1\" class=\"data row19 col1\" >DYNAMOS project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x792c97c01650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.29 s, sys: 314 ms, total: 2.6 s\n",
      "Wall time: 4.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "\n",
    "fablib.show_config();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=\"DYNAMOS-on-FABRIC\");\n",
    "nodes = slice.get_nodes();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: control\n",
      "  SSH Command from FABRIC: ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe84:397d\n",
      "  SSH Command locally (ensuring it is saved according to below steps): ssh -i ~/.ssh_fabric/slice_key -F ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe84:397d\n",
      "Node: dynamos\n",
      "  SSH Command from FABRIC: ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe1b:63f7\n",
      "  SSH Command locally (ensuring it is saved according to below steps): ssh -i ~/.ssh_fabric/slice_key -F ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe1b:63f7\n",
      "Node: server\n",
      "  SSH Command from FABRIC: ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe08:6a6e\n",
      "  SSH Command locally (ensuring it is saved according to below steps): ssh -i ~/.ssh_fabric/slice_key -F ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe08:6a6e\n",
      "Node: clientone\n",
      "  SSH Command from FABRIC: ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe91:6d37\n",
      "  SSH Command locally (ensuring it is saved according to below steps): ssh -i ~/.ssh_fabric/slice_key -F ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe91:6d37\n",
      "Node: clienttwo\n",
      "  SSH Command from FABRIC: ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe95:daf0\n",
      "  SSH Command locally (ensuring it is saved according to below steps): ssh -i ~/.ssh_fabric/slice_key -F ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fe95:daf0\n",
      "Node: clientthree\n",
      "  SSH Command from FABRIC: ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fead:1f7e\n",
      "  SSH Command locally (ensuring it is saved according to below steps): ssh -i ~/.ssh_fabric/slice_key -F ssh_config ubuntu@2001:400:a100:3070:f816:3eff:fead:1f7e\n"
     ]
    }
   ],
   "source": [
    "# Print the necessary information\n",
    "try:\n",
    "    # Get slice nodes\n",
    "    for node in slice.get_nodes():\n",
    "        print(f\"Node: {node.get_name()}\")\n",
    "        # Get the original SSH command\n",
    "        original_ssh_command = node.get_ssh_command()\n",
    "        # Print SSH commands to get into the nodes\n",
    "        print(f\"  SSH Command from FABRIC: {original_ssh_command}\")\n",
    "        # Replace the file paths in the SSH command\n",
    "        updated_ssh_command = original_ssh_command.replace(\n",
    "            \"/home/fabric/work/fabric_config/slice_key\", \"~/.ssh_fabric/slice_key\"\n",
    "        ).replace(\n",
    "            \"/home/fabric/work/fabric_config/ssh_config\", \"ssh_config\"\n",
    "        )\n",
    "        # Print the updated SSH command\n",
    "        print(f\"  SSH Command locally (ensuring it is saved according to below steps): {updated_ssh_command}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fail: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control: 10.137.3.2\n",
      "dynamos: 10.137.3.3\n",
      "server: 10.137.3.4\n",
      "clientone: 10.137.3.5\n",
      "clienttwo: 10.137.3.6\n",
      "clientthree: 10.137.3.7\n",
      "{'control': {'ip': '10.137.3.2', 'node': <fabrictestbed_extensions.fablib.node.Node object at 0x7ab589e09050>}, 'dynamos': {'ip': '10.137.3.3', 'node': <fabrictestbed_extensions.fablib.node.Node object at 0x7ab5a4f1dad0>}, 'server': {'ip': '10.137.3.4', 'node': <fabrictestbed_extensions.fablib.node.Node object at 0x7ab5544f6d50>}, 'clientone': {'ip': '10.137.3.5', 'node': <fabrictestbed_extensions.fablib.node.Node object at 0x7ab56c063350>}, 'clienttwo': {'ip': '10.137.3.6', 'node': <fabrictestbed_extensions.fablib.node.Node object at 0x7ab554379cd0>}, 'clientthree': {'ip': '10.137.3.7', 'node': <fabrictestbed_extensions.fablib.node.Node object at 0x7ab5661d2d50>}}\n"
     ]
    }
   ],
   "source": [
    "def get_ip(node):\n",
    "    interface = node.get_interface(network_name=f\"Network-{node.get_site()}\")\n",
    "    return interface.get_ip_addr()\n",
    "\n",
    "nodes_dict= dict()\n",
    "\n",
    "for node in nodes[:]:\n",
    "    ip = get_ip(node)\n",
    "    name = node.get_name()\n",
    "    nodes_dict[name] = {\"ip\": ip, \"node\": node}\n",
    "    print(f\"{name}: {ip}\")\n",
    "\n",
    "print(nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for resetting the kubespray cluster. \n",
    "# Use this if you are troubleshooting your Kubernetes cluster\n",
    "# and you want to redeploy fresh.\n",
    "\n",
    "# nodes_dict['control']['node'].upload_file(local_file_path=\"node_scripts/reset_kubespray.sh\", remote_file_path=\"reset.sh\");\n",
    "# nodes_dict['control']['node'].execute(f\"chmod +x reset.sh && ./reset.sh\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant etcd data to the dynamos node (update etcd agreements etc)\n",
    "\n",
    "# help(nodes_dict['dynamos']['node'])\n",
    "# upload etcd files from filesystem instead of reading them from github\n",
    "# nodes_dict['dynamos']['node'].upload_directory(local_directory_path=\"../configuration/etcd_launch_files\", remote_directory_path=\"./\")\n",
    "# nodes_dict['dynamos']['node'].execute(\"ls etcd_launch_files\")\n",
    "\n",
    "# nodes_dict['dynamos']['node'].upload_file(local_file_path=\"node_scripts/define_etcd_data_local.sh\", remote_file_path=\"define_etcd_data_local.sh\");\n",
    "# nodes_dict['dynamos']['node'].execute(f\"chmod +x define_etcd_data_local.sh && ./define_etcd_data_local.sh\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:\u001b[0m\u001b[31m--:-- --:--:--     0*   Trying 10.137.3.3:31203...\n",
      "* Connected to 10.137.3.3 (10.137.3.3) port 31203\n",
      "> POST /api/v1/requestApproval HTTP/1.1\n",
      "> Host: api-gateway.api-gateway.svc.cluster.local\n",
      "> User-Agent: curl/8.5.0\n",
      "> Accept: */*\n",
      "\u001b[0m\u001b[31m> Content-Type: application/json\n",
      "> Content-Length: 408\n",
      "> \n",
      "} [408 bytes data]\n",
      "100   408    0     0  100   408      0      6  0:01:08  0:00:59  0:00:09     0\u001b[0m  407\u001b[0m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m\u001b[31m<html>\n",
      "<head><title>504 Gateway Time-out</title></head>\n",
      "<body>\n",
      "<center><h1>504 Gateway Time-out</h1></center>\n",
      "<hr><center>nginx/1.25.1</center>\n",
      "</body>\n",
      "</html>\n",
      "\u001b[31m< HTTP/1.1 504 Gateway Time-out\n",
      "< Server: nginx/1.25.1\n",
      "< Date: Tue, 23 Sep 2025 11:37:21 GMT\n",
      "< Content-Type: text/html\n",
      "< Content-Length: 167\n",
      "< Connection: keep-alive\n",
      "< \n",
      "{ [167 bytes data]\n",
      "100   575  100   167  100   408      2      6  0:01:23  0:01:00  0:00:23    41\n",
      "* Connection #0 to host 10.137.3.3 left intact\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('<html>\\r\\n<head><title>504 Gateway Time-out</title></head>\\r\\n<body>\\r\\n<center><h1>504 Gateway Time-out</h1></center>\\r\\n<hr><center>nginx/1.25.1</center>\\r\\n</body>\\r\\n</html>\\r\\n',\n",
       " '  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 10.137.3.3:31203...\\n* Connected to 10.137.3.3 (10.137.3.3) port 31203\\n> POST /api/v1/requestApproval HTTP/1.1\\r\\n> Host: api-gateway.api-gateway.svc.cluster.local\\r\\n> User-Agent: curl/8.5.0\\r\\n> Accept: */*\\r\\n> Content-Type: application/json\\r\\n> Content-Length: 408\\r\\n> \\r\\n} [408 bytes data]\\n\\r100   408    0     0  100   408      0    407  0:00:01  0:00:01 --:--:--   407\\r100   408    0     0  100   408      0    203  0:00:02  0:00:02 --:--:--   203\\r100   408    0     0  100   408      0    135  0:00:03  0:00:03 --:--:--   135\\r100   408    0     0  100   408      0    101  0:00:04  0:00:04 --:--:--   101\\r100   408    0     0  100   408      0     81  0:00:05  0:00:05 --:--:--    81\\r100   408    0     0  100   408      0     67  0:00:06  0:00:06 --:--:--     0\\r100   408    0     0  100   408      0     58  0:00:07  0:00:07 --:--:--     0\\r100   408    0     0  100   408      0     50  0:00:08  0:00:08 --:--:--     0\\r100   408    0     0  100   408      0     45  0:00:09  0:00:09 --:--:--     0\\r100   408    0     0  100   408      0     40  0:00:10  0:00:10 --:--:--     0\\r100   408    0     0  100   408      0     37  0:00:11  0:00:11 --:--:--     0\\r100   408    0     0  100   408      0     33  0:00:12  0:00:12 --:--:--     0\\r100   408    0     0  100   408      0     31  0:00:13  0:00:13 --:--:--     0\\r100   408    0     0  100   408      0     29  0:00:14  0:00:14 --:--:--     0\\r100   408    0     0  100   408      0     27  0:00:15  0:00:15 --:--:--     0\\r100   408    0     0  100   408      0     25  0:00:16  0:00:16 --:--:--     0\\r100   408    0     0  100   408      0     23  0:00:17  0:00:17 --:--:--     0\\r100   408    0     0  100   408      0     22  0:00:18  0:00:18 --:--:--     0\\r100   408    0     0  100   408      0     21  0:00:19  0:00:19 --:--:--     0\\r100   408    0     0  100   408      0     20  0:00:20  0:00:20 --:--:--     0\\r100   408    0     0  100   408      0     19  0:00:21  0:00:21 --:--:--     0\\r100   408    0     0  100   408      0     18  0:00:22  0:00:22 --:--:--     0\\r100   408    0     0  100   408      0     17  0:00:24  0:00:23  0:00:01     0\\r100   408    0     0  100   408      0     16  0:00:25  0:00:24  0:00:01     0\\r100   408    0     0  100   408      0     16  0:00:25  0:00:25 --:--:--     0\\r100   408    0     0  100   408      0     15  0:00:27  0:00:26  0:00:01     0\\r100   408    0     0  100   408      0     15  0:00:27  0:00:27 --:--:--     0\\r100   408    0     0  100   408      0     14  0:00:29  0:00:28  0:00:01     0\\r100   408    0     0  100   408      0     14  0:00:29  0:00:29 --:--:--     0\\r100   408    0     0  100   408      0     13  0:00:31  0:00:30  0:00:01     0\\r100   408    0     0  100   408      0     13  0:00:31  0:00:31 --:--:--     0\\r100   408    0     0  100   408      0     12  0:00:34  0:00:32  0:00:02     0\\r100   408    0     0  100   408      0     12  0:00:34  0:00:33  0:00:01     0\\r100   408    0     0  100   408      0     11  0:00:37  0:00:34  0:00:03     0\\r100   408    0     0  100   408      0     11  0:00:37  0:00:35  0:00:02     0\\r100   408    0     0  100   408      0     11  0:00:37  0:00:36  0:00:01     0\\r100   408    0     0  100   408      0     11  0:00:37  0:00:37 --:--:--     0\\r100   408    0     0  100   408      0     10  0:00:40  0:00:38  0:00:02     0\\r100   408    0     0  100   408      0     10  0:00:40  0:00:39  0:00:01     0\\r100   408    0     0  100   408      0     10  0:00:40  0:00:40 --:--:--     0\\r100   408    0     0  100   408      0      9  0:00:45  0:00:41  0:00:04     0\\r100   408    0     0  100   408      0      9  0:00:45  0:00:42  0:00:03     0\\r100   408    0     0  100   408      0      9  0:00:45  0:00:43  0:00:02     0\\r100   408    0     0  100   408      0      9  0:00:45  0:00:44  0:00:01     0\\r100   408    0     0  100   408      0      9  0:00:45  0:00:45 --:--:--     0\\r100   408    0     0  100   408      0      8  0:00:51  0:00:46  0:00:05     0\\r100   408    0     0  100   408      0      8  0:00:51  0:00:47  0:00:04     0\\r100   408    0     0  100   408      0      8  0:00:51  0:00:48  0:00:03     0\\r100   408    0     0  100   408      0      8  0:00:51  0:00:49  0:00:02     0\\r100   408    0     0  100   408      0      8  0:00:51  0:00:50  0:00:01     0\\r100   408    0     0  100   408      0      7  0:00:58  0:00:51  0:00:07     0\\r100   408    0     0  100   408      0      7  0:00:58  0:00:52  0:00:06     0\\r100   408    0     0  100   408      0      7  0:00:58  0:00:53  0:00:05     0\\r100   408    0     0  100   408      0      7  0:00:58  0:00:54  0:00:04     0\\r100   408    0     0  100   408      0      7  0:00:58  0:00:55  0:00:03     0\\r100   408    0     0  100   408      0      7  0:00:58  0:00:56  0:00:02     0\\r100   408    0     0  100   408      0      7  0:00:58  0:00:57  0:00:01     0\\r100   408    0     0  100   408      0      7  0:00:58  0:00:58 --:--:--     0\\r100   408    0     0  100   408      0      6  0:01:08  0:00:59  0:00:09     0< HTTP/1.1 504 Gateway Time-out\\r\\n< Server: nginx/1.25.1\\r\\n< Date: Tue, 23 Sep 2025 11:37:21 GMT\\r\\n< Content-Type: text/html\\r\\n< Content-Length: 167\\r\\n< Connection: keep-alive\\r\\n< \\r\\n{ [167 bytes data]\\n\\r100   575  100   167  100   408      2      6  0:01:23  0:01:00  0:00:23    33\\r100   575  100   167  100   408      2      6  0:01:23  0:01:00  0:00:23    41\\n* Connection #0 to host 10.137.3.3 left intact\\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Run the trigger script\n",
    "# note: could make it so that ignores the output > null \n",
    "nodes_dict['control']['node'].upload_file(local_file_path=\"node_scripts/trigger_VFL.sh\", remote_file_path=\"trigger_VFL.sh\")\n",
    "\n",
    "nodes_dict['control']['node'].execute(\"bash trigger_VFL.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.86614173228347\n",
      "71.65354330708661\n",
      "71.9910011248594\n",
      "72.55343082114736\n",
      "72.77840269966255\n",
      "72.77840269966255\n",
      "73.3408323959505\n",
      "73.67829021372329\n",
      "73.56580427446569\n",
      "73.56580427446569\n",
      "74.01574803149606\n",
      "74.12823397075366\n",
      "74.46569178852643\n",
      "74.80314960629921\n",
      "74.69066366704162\n",
      "74.69066366704162\n",
      "75.14060742407199\n",
      "75.14060742407199\n",
      "75.0281214848144\n",
      "CPU times: user 56.2 ms, sys: 13.6 ms, total: 69.8 ms\n",
      "Wall time: 5.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('70.86614173228347\\n71.65354330708661\\n71.9910011248594\\n72.55343082114736\\n72.77840269966255\\n72.77840269966255\\n73.3408323959505\\n73.67829021372329\\n73.56580427446569\\n73.56580427446569\\n74.01574803149606\\n74.12823397075366\\n74.46569178852643\\n74.80314960629921\\n74.69066366704162\\n74.69066366704162\\n75.14060742407199\\n75.14060742407199\\n75.0281214848144\\n',\n",
       " '')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: read the metrics based on the other script \n",
    "\n",
    "nodes_dict['control']['node'].upload_file(local_file_path=\"../scripts/retrieve_data.sh\", remote_file_path=\"retrieve_data.sh\")\n",
    "nodes_dict['control']['node'].execute(f\"bash retrieve_data.sh {2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading the node setup...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<SFTPAttributes: [ size=1222 uid=1000 gid=1000 mode=0o100664 atime=1758572167 mtime=1758572168 ]>,\n",
       " <SFTPAttributes: [ size=1222 uid=1000 gid=1000 mode=0o100664 atime=1758572165 mtime=1758572165 ]>,\n",
       " <SFTPAttributes: [ size=1222 uid=1000 gid=1000 mode=0o100664 atime=1758572165 mtime=1758572165 ]>,\n",
       " <SFTPAttributes: [ size=1222 uid=1000 gid=1000 mode=0o100664 atime=1758572165 mtime=1758572165 ]>,\n",
       " <SFTPAttributes: [ size=1222 uid=1000 gid=1000 mode=0o100664 atime=1758572165 mtime=1758572165 ]>,\n",
       " <SFTPAttributes: [ size=1222 uid=1000 gid=1000 mode=0o100664 atime=1758572167 mtime=1758572168 ]>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we need to do it everytime?? I don;t think so but I should test \n",
    "\n",
    "slice = fablib.get_slice(name=\"DYNAMOS-on-FABRIC\");\n",
    "nodes = slice.get_nodes();\n",
    "\n",
    "for node in nodes:\n",
    "    ssh_command = node.get_ssh_command().replace(\n",
    "        \"-i /home/fabric/work/fabric_config/slice_key\", \"-i ~/.ssh/keys/FABRIC-slice_key\"\n",
    "    ).replace(\n",
    "        \"-F /home/fabric/work/fabric_config/ssh_config \", \"\"\n",
    "    )\n",
    "    \n",
    "    print(ssh_command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding agents...\n",
      "- agent 'server'\n",
      "- agent 'clientone'\n",
      "- agent 'clienttwo'\n",
      "- agent 'clientthree'\n",
      "\n",
      "Adding third parties...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configure DYNAMOS for the FABRIC nodes\n",
    "# agents_string = \",\".join(agents)\n",
    "# thirdparties_string = \",\".join(thirdparties)\n",
    "\n",
    "\n",
    "# nodes_dict['control']['node'].upload_file(local_file_path=\"node_scripts/configure_dynamos.sh\", remote_file_path=\"configure_dynamos.sh\");\n",
    "# nodes_dict['control']['node'].execute(f\"chmod +x configure_dynamos.sh && ./configure_dynamos.sh {agents_string} {thirdparties_string}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally override the installation scripts \n",
    "# nodes_dict['control']['node'].upload_file(local_file_path=\"../configuration/dynamos-configuration.sh\", remote_file_path=\"/home/ubuntu/DYNAMOS/configuration/dynamos-configuration.sh\")\n",
    "# nodes_dict['control']['node'].upload_file(local_file_path=\"../configuration/fill-rabbit-pvc.sh\", remote_file_path=\"/home/ubuntu/DYNAMOS/configuration/fill-rabbit-pvc.sh\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DYNAMOS configuration v0.1.2\n",
      "Setting up paths...\n",
      "definitions_example.json copied over definitions.json to ensure a clean file\n",
      "Generating RabbitMQ password...\n",
      "Replacing tokens...\n",
      "Installing namespaces...\n",
      "Release \"namespaces\" does not exist. Installing it now.\n",
      "NAME: namespaces\n",
      "LAST DEPLOYED: Tue Sep 23 11:33:50 2025\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "Preparing PVC\n",
      "fill-pvc v0.1.2\n",
      "pod/temp-pod created\n",
      "pod/temp-pod-orch created\n",
      "Waiting for temp-pod to be Running...\n",
      "pod/temp-pod condition met\n",
      "pod/temp-pod-orch condition met\n",
      "pod \"temp-pod\" deleted\n",
      "pod \"temp-pod-orch\" deleted\n",
      "Installing Prometheus...\n",
      "\"prometheus-community\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "Release \"prometheus\" does not exist. Installing it now.\n",
      "NAME: prometheus\n",
      "LAST DEPLOYED: Tue Sep 23 11:34:46 2025\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "NOTES:\n",
      "kube-prometheus-stack has been installed. Check its status by running:\n",
      "  kubectl --namespace default get pods -l \"release=prometheus\"\n",
      "\n",
      "Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create & configure Alertmanager and Prometheus instances using the Operator.\n",
      "Installing NGINX...\n",
      "\u001b[31mPulled: ghcr.io/nginxinc/charts/nginx-ingress:0.18.0\n",
      "Digest: sha256:662500f896f15a142b9ae04e469ae620a88de12dbcacbc8a0f944ce11e5038e1\n",
      "\u001b[0mRelease \"nginx\" has been upgraded. Happy Helming!\n",
      "NAME: nginx\n",
      "LAST DEPLOYED: Tue Sep 23 11:34:58 2025\n",
      "NAMESPACE: ingress\n",
      "STATUS: deployed\n",
      "REVISION: 5\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "The NGINX Ingress Controller has been installed.\n",
      "Installing DYNAMOS core...\n",
      "Release \"core\" does not exist. Installing it now.\n",
      "NAME: core\n",
      "LAST DEPLOYED: Tue Sep 23 11:34:59 2025\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "Release \"orchestrator\" does not exist. Installing it now.\n",
      "NAME: orchestrator\n",
      "LAST DEPLOYED: Tue Sep 23 11:35:02 2025\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "Installing agents layer\n",
      "Release \"agents\" does not exist. Installing it now.\n",
      "NAME: agents\n",
      "LAST DEPLOYED: Tue Sep 23 11:35:03 2025\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "Installing thirdparty layer...\n",
      "Release \"thirdparties\" does not exist. Installing it now.\n",
      "NAME: thirdparties\n",
      "LAST DEPLOYED: Tue Sep 23 11:35:05 2025\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "Installing api gateway\n",
      "Release \"api-gateway\" does not exist. Installing it now.\n",
      "NAME: api-gateway\n",
      "LAST DEPLOYED: Tue Sep 23 11:35:06 2025\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "Finished setting up DYNAMOS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('DYNAMOS configuration v0.1.2\\nSetting up paths...\\ndefinitions_example.json copied over definitions.json to ensure a clean file\\nGenerating RabbitMQ password...\\nReplacing tokens...\\nInstalling namespaces...\\nRelease \"namespaces\" does not exist. Installing it now.\\nNAME: namespaces\\nLAST DEPLOYED: Tue Sep 23 11:33:50 2025\\nNAMESPACE: default\\nSTATUS: deployed\\nREVISION: 1\\nTEST SUITE: None\\nPreparing PVC\\nfill-pvc v0.1.2\\npod/temp-pod created\\npod/temp-pod-orch created\\nWaiting for temp-pod to be Running...\\npod/temp-pod condition met\\npod/temp-pod-orch condition met\\npod \"temp-pod\" deleted\\npod \"temp-pod-orch\" deleted\\nInstalling Prometheus...\\n\"prometheus-community\" already exists with the same configuration, skipping\\nHang tight while we grab the latest from your chart repositories...\\n...Successfully got an update from the \"prometheus-community\" chart repository\\nUpdate Complete. ⎈Happy Helming!⎈\\nRelease \"prometheus\" does not exist. Installing it now.\\nNAME: prometheus\\nLAST DEPLOYED: Tue Sep 23 11:34:46 2025\\nNAMESPACE: default\\nSTATUS: deployed\\nREVISION: 1\\nNOTES:\\nkube-prometheus-stack has been installed. Check its status by running:\\n  kubectl --namespace default get pods -l \"release=prometheus\"\\n\\nVisit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create & configure Alertmanager and Prometheus instances using the Operator.\\nInstalling NGINX...\\nRelease \"nginx\" has been upgraded. Happy Helming!\\nNAME: nginx\\nLAST DEPLOYED: Tue Sep 23 11:34:58 2025\\nNAMESPACE: ingress\\nSTATUS: deployed\\nREVISION: 5\\nTEST SUITE: None\\nNOTES:\\nThe NGINX Ingress Controller has been installed.\\nInstalling DYNAMOS core...\\nRelease \"core\" does not exist. Installing it now.\\nNAME: core\\nLAST DEPLOYED: Tue Sep 23 11:34:59 2025\\nNAMESPACE: default\\nSTATUS: deployed\\nREVISION: 1\\nTEST SUITE: None\\nRelease \"orchestrator\" does not exist. Installing it now.\\nNAME: orchestrator\\nLAST DEPLOYED: Tue Sep 23 11:35:02 2025\\nNAMESPACE: default\\nSTATUS: deployed\\nREVISION: 1\\nTEST SUITE: None\\nInstalling agents layer\\nRelease \"agents\" does not exist. Installing it now.\\nNAME: agents\\nLAST DEPLOYED: Tue Sep 23 11:35:03 2025\\nNAMESPACE: default\\nSTATUS: deployed\\nREVISION: 1\\nTEST SUITE: None\\nInstalling thirdparty layer...\\nRelease \"thirdparties\" does not exist. Installing it now.\\nNAME: thirdparties\\nLAST DEPLOYED: Tue Sep 23 11:35:05 2025\\nNAMESPACE: default\\nSTATUS: deployed\\nREVISION: 1\\nTEST SUITE: None\\nInstalling api gateway\\nRelease \"api-gateway\" does not exist. Installing it now.\\nNAME: api-gateway\\nLAST DEPLOYED: Tue Sep 23 11:35:06 2025\\nNAMESPACE: default\\nSTATUS: deployed\\nREVISION: 1\\nTEST SUITE: None\\nFinished setting up DYNAMOS\\n',\n",
       " 'Pulled: ghcr.io/nginxinc/charts/nginx-ingress:0.18.0\\nDigest: sha256:662500f896f15a142b9ae04e469ae620a88de12dbcacbc8a0f944ce11e5038e1\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install DYNAMOS\n",
    "nodes_dict['control']['node'].execute(f\"~/DYNAMOS/configuration/dynamos-configuration.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"agents\" uninstalled\n",
      "release \"api-gateway\" uninstalled\n",
      "release \"core\" uninstalled\n",
      "release \"orchestrator\" uninstalled\n",
      "These resources were kept due to the resource policy:\n",
      "[Namespace] core\n",
      "[Namespace] orchestrator\n",
      "[Namespace] clienttwo\n",
      "[Namespace] clientthree\n",
      "[Namespace] uva\n",
      "[Namespace] vu\n",
      "[Namespace] surf\n",
      "[Namespace] ingress\n",
      "[Namespace] api-gateway\n",
      "[Namespace] alpha\n",
      "[Namespace] server\n",
      "[Namespace] clientone\n",
      "\n",
      "release \"namespaces\" uninstalled\n",
      "release \"prometheus\" uninstalled\n",
      "release \"thirdparties\" uninstalled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('release \"agents\" uninstalled\\nrelease \"api-gateway\" uninstalled\\nrelease \"core\" uninstalled\\nrelease \"orchestrator\" uninstalled\\nThese resources were kept due to the resource policy:\\n[Namespace] core\\n[Namespace] orchestrator\\n[Namespace] clienttwo\\n[Namespace] clientthree\\n[Namespace] uva\\n[Namespace] vu\\n[Namespace] surf\\n[Namespace] ingress\\n[Namespace] api-gateway\\n[Namespace] alpha\\n[Namespace] server\\n[Namespace] clientone\\n\\nrelease \"namespaces\" uninstalled\\nrelease \"prometheus\" uninstalled\\nrelease \"thirdparties\" uninstalled\\n',\n",
       " '')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional to clean up: uninstall DYNAMOS\n",
    "\n",
    "command = \"helm uninstall agents api-gateway core orchestrator namespaces prometheus thirdparties\"\n",
    "# nodes_dict['control']['node'].execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace \"clientone\" deleted\n",
      "namespace \"clienttwo\" deleted\n",
      "namespace \"clientthree\" deleted\n",
      "namespace \"server\" deleted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('namespace \"clientone\" deleted\\nnamespace \"clienttwo\" deleted\\nnamespace \"clientthree\" deleted\\nnamespace \"server\" deleted\\n',\n",
       " '')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uninstall client and server namespaces (sometimes is needed)\n",
    "command = \"kubectl delete namespace clientone clienttwo clientthree server\"\n",
    "# nodes_dict['control']['node'].execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional delete etcd PVCs \n",
    "# nodes_dict['control']['node'].execute(\"kubectl get pvc --all-namespaces\")\n",
    "\n",
    "# nodes_dict['control']['node'].execute(\"kubectl delete pvc etcd-data-etcd-0 -n core\")\n",
    "# nodes_dict['control']['node'].execute(\"kubectl delete pvc etcd-data-etcd-1 -n core\")\n",
    "# nodes_dict['control']['node'].execute(\"kubectl delete pvc etcd-data-etcd-2 -n core\")\n",
    "\n",
    "\n",
    "# nodes_dict['control']['node'].execute(\"kubectl get pvc --all-namespaces\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
